{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9d3af3a-125f-4798-8862-9f19fa779a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading BTCUSDT: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 302/302 [02:09<00:00,  2.33day/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Missing file: BTCUSDT-trades-2025-10-23.parquet\n",
      "[WARNING] Missing file: BTCUSDT-trades-2025-10-24.parquet\n",
      "[WARNING] Missing file: BTCUSDT-trades-2025-10-25.parquet\n",
      "[WARNING] Missing file: BTCUSDT-trades-2025-10-26.parquet\n",
      "[WARNING] Missing file: BTCUSDT-trades-2025-10-27.parquet\n",
      "[WARNING] Missing file: BTCUSDT-trades-2025-10-28.parquet\n",
      "[WARNING] Missing file: BTCUSDT-trades-2025-10-29.parquet\n",
      "Loaded data with 7080 rows\n",
      "After feature engineering: 7059 rows\n",
      "Using 16 features: ['sma_5', 'sma_20', 'volatility_20', 'price_position', 'momentum_5', 'momentum_10', 'log_return_lag_1', 'log_return_lag_2', 'log_return_lag_3', 'log_return_lag_4', 'log_return_lag_5', 'log_return_lag_6', 'log_return_lag_7', 'log_return_lag_8', 'rsi_14', 'volatility_ratio']\n",
      "Model created with 13059 parameters\n",
      "Training model...\n",
      "Epoch 0: Train Loss: 1.0800, Val Loss: 0.9819, LR: 0.001000\n",
      "Epoch 20: Train Loss: 1.0055, Val Loss: 0.9642, LR: 0.001000\n",
      "Early stopping at epoch 33\n",
      "Test Accuracy: 56.87%\n",
      "Running backtest...\n",
      "Initial Capital: $10,000\n",
      "Final Portfolio Value: $9642.74\n",
      "Total Return: -3.57%\n",
      "Number of Trades: 75\n",
      "Strategy completed successfully!\n",
      "Total Return: -3.57%\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import research\n",
    "import datetime\n",
    "\n",
    "# Fix the data loading issue first\n",
    "def load_data_safely(sym, time_interval, start_date, end_date):\n",
    "    \"\"\"Load data with proper error handling\"\"\"\n",
    "    try:\n",
    "        ts = research.load_ohlc_timeseries_range(sym, time_interval, start_date, end_date)\n",
    "        return ts\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        # Alternative: Use available data or synthetic data for testing\n",
    "        return create_sample_data()\n",
    "\n",
    "def create_sample_data():\n",
    "    \"\"\"Create sample data for testing when real data is unavailable\"\"\"\n",
    "    dates = pl.datetime_range(\n",
    "        start=datetime.datetime(2024, 1, 1),\n",
    "        end=datetime.datetime(2024, 10, 29),\n",
    "        interval=\"1h\",\n",
    "        eager=True\n",
    "    )\n",
    "    \n",
    "    # Create realistic price data with trends and volatility\n",
    "    np.random.seed(42)\n",
    "    n = len(dates)\n",
    "    returns = np.random.normal(0.0001, 0.01, n)  # Small positive drift\n",
    "    prices = 50000 * np.cumprod(1 + returns)\n",
    "    \n",
    "    # Add some realistic OHLC structure\n",
    "    data = {\n",
    "        'datetime': dates,\n",
    "        'open': prices * (1 + np.random.normal(0, 0.001, n)),\n",
    "        'high': prices * (1 + np.abs(np.random.normal(0.002, 0.002, n))),\n",
    "        'low': prices * (1 - np.abs(np.random.normal(0.002, 0.002, n))),\n",
    "        'close': prices\n",
    "    }\n",
    "    \n",
    "    return pl.DataFrame(data)\n",
    "\n",
    "# Enhanced Feature Engineering\n",
    "def create_advanced_features(ts, target='close', lags=10, forecast_horizon=1):\n",
    "    \"\"\"Create comprehensive feature set for time series prediction\"\"\"\n",
    "    \n",
    "    ts = ts.with_columns([\n",
    "        # Basic price transformations\n",
    "        (pl.col('close') / pl.col('close').shift(1)).log().alias('log_return'),\n",
    "        pl.col('close').pct_change().alias('return'),\n",
    "        \n",
    "        # Rolling statistics\n",
    "        pl.col('close').rolling_mean(window_size=5).alias('sma_5'),\n",
    "        pl.col('close').rolling_mean(window_size=20).alias('sma_20'),\n",
    "        pl.col('close').rolling_std(window_size=20).alias('volatility_20'),\n",
    "        \n",
    "        # Price position relative to range\n",
    "        ((pl.col('close') - pl.col('low')) / (pl.col('high') - pl.col('low') + 1e-8)).alias('price_position'),\n",
    "        \n",
    "        # Momentum indicators\n",
    "        (pl.col('close') / pl.col('close').shift(5) - 1).alias('momentum_5'),\n",
    "        (pl.col('close') / pl.col('close').shift(10) - 1).alias('momentum_10'),\n",
    "    ])\n",
    "    \n",
    "    # Add lagged features for returns\n",
    "    for i in range(1, lags + 1):\n",
    "        ts = ts.with_columns([\n",
    "            pl.col('log_return').shift(i).alias(f'log_return_lag_{i}')\n",
    "        ])\n",
    "    \n",
    "    # Technical indicators\n",
    "    ts = ts.with_columns([\n",
    "        # RSI approximation (14-period)\n",
    "        pl.when(pl.col('log_return') > 0)\n",
    "        .then(pl.col('log_return'))\n",
    "        .otherwise(0)\n",
    "        .rolling_sum(14)\n",
    "        .alias('gain'),\n",
    "        \n",
    "        pl.when(pl.col('log_return') < 0)\n",
    "        .then(-pl.col('log_return'))\n",
    "        .otherwise(0)\n",
    "        .rolling_sum(14)\n",
    "        .alias('loss')\n",
    "    ])\n",
    "    \n",
    "    ts = ts.with_columns([\n",
    "        (100 - (100 / (1 + (pl.col('gain') / (pl.col('loss') + 1e-8))))).alias('rsi_14'),\n",
    "        \n",
    "        # Volatility regime\n",
    "        (pl.col('log_return').rolling_std(5) / \n",
    "         (pl.col('log_return').rolling_std(20) + 1e-8)).alias('volatility_ratio'),\n",
    "    ])\n",
    "    \n",
    "    # Target variable\n",
    "    ts = ts.with_columns([\n",
    "        pl.col('log_return').shift(-forecast_horizon).alias('target_log_return')\n",
    "    ])\n",
    "    \n",
    "    return ts.drop_nulls()\n",
    "\n",
    "# Improved Model Architecture\n",
    "class ImprovedMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[128, 64, 32], dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Output: 3 classes (sell, hold, buy)\n",
    "        layers.append(nn.Linear(prev_dim, 3))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Fixed Training Function\n",
    "def train_model_advanced(model, train_loader, val_loader, criterion, optimizer, num_epochs=100):\n",
    "    \"\"\"Enhanced training with early stopping and learning rate scheduling\"\"\"\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience = 15\n",
    "    patience_counter = 0\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=8, factor=0.5)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                outputs = model(batch_x)\n",
    "                val_loss += criterion(outputs, batch_y).item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "            \n",
    "        if epoch % 20 == 0:\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f'Epoch {epoch}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, LR: {current_lr:.6f}')\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "def create_regime_labels(returns, thresholds=[-0.002, 0.002]):\n",
    "    \"\"\"Create classification labels based on return regimes\"\"\"\n",
    "    labels = []\n",
    "    for ret in returns:\n",
    "        if ret < thresholds[0]:\n",
    "            labels.append(0)  # Sell (strong negative)\n",
    "        elif ret > thresholds[1]:\n",
    "            labels.append(2)  # Buy (strong positive)\n",
    "        else:\n",
    "            labels.append(1)  # Hold (neutral)\n",
    "    return np.array(labels)\n",
    "\n",
    "def prepare_data_for_training(ts, feature_columns, test_size=0.2, val_size=0.1, batch_size=32):\n",
    "    \"\"\"Prepare data for neural network training\"\"\"\n",
    "    # Filter out any remaining nulls\n",
    "    ts_clean = ts.drop_nulls()\n",
    "    \n",
    "    # Extract features and targets\n",
    "    X = ts_clean[feature_columns].to_numpy().astype(np.float32)\n",
    "    y = create_regime_labels(ts_clean['target_log_return'].to_numpy())\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split data\n",
    "    total_size = len(X_scaled)\n",
    "    test_start = int(total_size * (1 - test_size - val_size))\n",
    "    val_start = int(total_size * (1 - test_size))\n",
    "    \n",
    "    X_train = X_scaled[:test_start]\n",
    "    X_val = X_scaled[test_start:val_start]\n",
    "    X_test = X_scaled[val_start:]\n",
    "    \n",
    "    y_train = y[:test_start]\n",
    "    y_val = y[test_start:val_start]\n",
    "    y_test = y[val_start:]\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor(X_train, dtype=torch.float32),\n",
    "        torch.tensor(y_train, dtype=torch.long)\n",
    "    )\n",
    "    val_dataset = TensorDataset(\n",
    "        torch.tensor(X_val, dtype=torch.float32),\n",
    "        torch.tensor(y_val, dtype=torch.long)\n",
    "    )\n",
    "    test_dataset = TensorDataset(\n",
    "        torch.tensor(X_test, dtype=torch.float32),\n",
    "        torch.tensor(y_test, dtype=torch.long)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, scaler\n",
    "\n",
    "# Risk-Managed Trading Strategy\n",
    "class RiskManagedStrategy:\n",
    "    def __init__(self, initial_capital=10000, max_position_size=0.2, stop_loss=0.03):\n",
    "        self.capital = initial_capital\n",
    "        self.max_position_size = max_position_size\n",
    "        self.stop_loss = stop_loss\n",
    "        self.position = 0\n",
    "        self.entry_price = 0\n",
    "        self.trades = []\n",
    "        \n",
    "    def execute_trade(self, signal, confidence, current_price, volatility):\n",
    "        \"\"\"Execute trade with risk management\"\"\"\n",
    "        position_size = self.calculate_position_size(confidence, volatility)\n",
    "        \n",
    "        if signal == 0 and self.position > 0:  # Sell signal and we're long\n",
    "            # Close long position\n",
    "            pnl = (current_price - self.entry_price) / self.entry_price * self.position\n",
    "            self.capital *= (1 + pnl)\n",
    "            self.trades.append(('SELL', current_price, pnl))\n",
    "            self.position = 0\n",
    "            \n",
    "        elif signal == 2 and self.position == 0:  # Buy signal and no position\n",
    "            # Open long position\n",
    "            investment = self.capital * position_size\n",
    "            self.position = investment / current_price\n",
    "            self.entry_price = current_price\n",
    "            self.trades.append(('BUY', current_price, 0))\n",
    "            \n",
    "        elif signal == 0 and self.position == 0:  # Sell signal and no position\n",
    "            # Could implement short selling here\n",
    "            pass\n",
    "            \n",
    "        # Check stop loss\n",
    "        if self.position > 0:\n",
    "            current_pnl = (current_price - self.entry_price) / self.entry_price\n",
    "            if current_pnl < -self.stop_loss:\n",
    "                # Stop loss triggered\n",
    "                self.capital *= (1 + current_pnl)\n",
    "                self.trades.append(('STOP_LOSS', current_price, current_pnl))\n",
    "                self.position = 0\n",
    "    \n",
    "    def calculate_position_size(self, confidence, volatility):\n",
    "        \"\"\"Dynamic position sizing based on confidence and market volatility\"\"\"\n",
    "        base_size = self.max_position_size * confidence\n",
    "        # Reduce position size in high volatility\n",
    "        volatility_adjustment = 1.0 / (1.0 + volatility * 50)  # Adjust scaling factor\n",
    "        return min(base_size * volatility_adjustment, self.max_position_size)\n",
    "    \n",
    "    def get_portfolio_value(self, current_price):\n",
    "        \"\"\"Calculate current portfolio value\"\"\"\n",
    "        position_value = self.position * current_price if self.position > 0 else 0\n",
    "        return self.capital + position_value\n",
    "\n",
    "# Complete Improved Pipeline\n",
    "def run_enhanced_strategy(sym, time_interval, start_date, end_date):\n",
    "    \"\"\"Run the complete enhanced trading strategy\"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    \n",
    "    # Load and prepare data\n",
    "    ts = load_data_safely(sym, time_interval, start_date, end_date)\n",
    "    print(f\"Loaded data with {len(ts)} rows\")\n",
    "    \n",
    "    # Create features\n",
    "    ts = create_advanced_features(ts, lags=8)\n",
    "    print(f\"After feature engineering: {len(ts)} rows\")\n",
    "    \n",
    "    # Select features\n",
    "    feature_columns = [col for col in ts.columns if any(x in col for x in ['lag_', 'sma_', 'momentum', 'volatility', 'rsi', 'price_position'])]\n",
    "    print(f\"Using {len(feature_columns)} features: {feature_columns}\")\n",
    "    \n",
    "    # Prepare data for training\n",
    "    train_loader, val_loader, test_loader, scaler = prepare_data_for_training(\n",
    "        ts, feature_columns, test_size=0.2, val_size=0.1, batch_size=64\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    model = ImprovedMLP(input_dim=len(feature_columns))\n",
    "    print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "    \n",
    "    # Training setup\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Training model...\")\n",
    "    model, train_losses, val_losses = train_model_advanced(\n",
    "        model, train_loader, val_loader, criterion, optimizer, num_epochs=200\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            outputs = model(batch_x)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    # Backtest strategy\n",
    "    print(\"Running backtest...\")\n",
    "    backtest_results = backtest_strategy(model, scaler, ts, feature_columns)\n",
    "    \n",
    "    return backtest_results, model, train_losses, val_losses\n",
    "\n",
    "def backtest_strategy(model, scaler, ts, feature_columns):\n",
    "    \"\"\"Backtest the trading strategy\"\"\"\n",
    "    # Filter test period\n",
    "    test_start = int(len(ts) * 0.7)\n",
    "    ts_test = ts[test_start:].drop_nulls()\n",
    "    \n",
    "    if len(ts_test) == 0:\n",
    "        print(\"No test data available\")\n",
    "        return None\n",
    "    \n",
    "    # Prepare features\n",
    "    X_test = ts_test[feature_columns].to_numpy().astype(np.float32)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Get predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(torch.tensor(X_test_scaled, dtype=torch.float32))\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "    \n",
    "    # Run strategy\n",
    "    strategy = RiskManagedStrategy(initial_capital=10000)\n",
    "    prices = ts_test['close'].to_numpy()\n",
    "    \n",
    "    for i, (pred, price) in enumerate(zip(predictions, prices)):\n",
    "        if i >= 20:  # Wait for enough volatility data\n",
    "            volatility = ts_test['volatility_20'].to_numpy()[i]\n",
    "            confidence = torch.softmax(outputs[i], dim=0)[pred].item()\n",
    "            \n",
    "            strategy.execute_trade(pred.item(), confidence, price, volatility)\n",
    "    \n",
    "    final_value = strategy.get_portfolio_value(prices[-1])\n",
    "    total_return = (final_value - 10000) / 10000\n",
    "    \n",
    "    print(f\"Initial Capital: $10,000\")\n",
    "    print(f\"Final Portfolio Value: ${final_value:.2f}\")\n",
    "    print(f\"Total Return: {total_return:.2%}\")\n",
    "    print(f\"Number of Trades: {len(strategy.trades)}\")\n",
    "    \n",
    "    return {\n",
    "        'final_value': final_value,\n",
    "        'total_return': total_return,\n",
    "        'trades': strategy.trades,\n",
    "        'model': model\n",
    "    }\n",
    "\n",
    "# Run the enhanced strategy (with proper error handling)\n",
    "try:\n",
    "    results, model, train_losses, val_losses = run_enhanced_strategy(\n",
    "        'BTCUSDT', '1h', \n",
    "        datetime.datetime(2025, 1, 1), \n",
    "        datetime.datetime(2025, 10, 29)\n",
    "    )\n",
    "    \n",
    "    if results:\n",
    "        print(\"Strategy completed successfully!\")\n",
    "        print(f\"Total Return: {results['total_return']:.2%}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error running strategy: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (quant-trading)",
   "language": "python",
   "name": "quant-trading"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
